{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1128fd",
   "metadata": {},
   "source": [
    "# Pipeline Unit Tests\n",
    "This notebook uses the provided synthetic data to automatically validate the main pipeline utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51411f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import config\n",
    "from model_definitions import (\n",
    "    get_base_regressors, get_base_classifiers,\n",
    "    get_meta_regressor_candidates, get_meta_classifier_candidates,\n",
    "    optimize_lgbm_reg, optimize_lgbm_cls,\n",
    "    select_best_stack)\n",
    "from utils import run_optuna_study\n",
    "from outer_cv import run_outer_cv_loop\n",
    "from pipeline_steps import aggregate_cv_results, select_final_model, evaluate_on_test_set\n",
    "\n",
    "# Speed up tests\n",
    "config.N_SPLITS_OUTER_CV = 2\n",
    "config.OPTUNA_TRIALS_MAIN = 2\n",
    "config.OPTUNA_TRIALS_OTHER = 1\n",
    "config.TUNE_ALL_BASE_MODELS = False\n",
    "\n",
    "# Load synthetic dataset\n",
    "df = pd.read_csv(config.DATA_FILE)\n",
    "X = df.iloc[:, :-2]\n",
    "y_reg = df.iloc[:, -2]\n",
    "y_cls = df.iloc[:, -1]\n",
    "print(f\"Data shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=config.N_SPLITS_OUTER_CV, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "splits = list(kf.split(X))\n",
    "print(f'Number of folds: {len(splits)}')\n",
    "assert len(splits) == config.N_SPLITS_OUTER_CV\n",
    "combined = np.concatenate([fold[0] for fold in splits])\n",
    "assert set(combined) <= set(range(len(X)))\n",
    "print('Cross validation splitter works as expected.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7133f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna_study(\n",
    "    optimize_lgbm_reg,\n",
    "    X.iloc[:100], y_reg.iloc[:100],\n",
    "    X.iloc[100:150], y_reg.iloc[100:150],\n",
    "    n_trials=2, direction='minimize', study_name='test_lgbm_reg')\n",
    "assert study.best_trial is not None\n",
    "print(\"Optuna returned best params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2188962",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_regs = get_base_regressors()\n",
    "for name, model in base_regs.items():\n",
    "    model.fit(X.iloc[:150], y_reg.iloc[:150])\n",
    "    preds = model.predict(X.iloc[150:160])\n",
    "    assert len(preds) == 10\n",
    "print(\"Regression base models train and predict successfully.\")\n",
    "\n",
    "base_clfs = get_base_classifiers()\n",
    "for name, model in base_clfs.items():\n",
    "    model.fit(X.iloc[:150], y_cls.iloc[:150])\n",
    "    preds = model.predict(X.iloc[150:160])\n",
    "    assert len(preds) == 10\n",
    "print(\"Classification base models train and predict successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b08658",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_REGRESSORS = get_base_regressors()\n",
    "MODEL_CLASSIFIERS = get_base_classifiers()\n",
    "META_REG_CANDS = get_meta_regressor_candidates()\n",
    "META_CLS_CANDS = get_meta_classifier_candidates()\n",
    "OPT_FUNCS_REG = {'LGBM': optimize_lgbm_reg}\n",
    "OPT_FUNCS_CLS = {'LGBM': optimize_lgbm_cls}\n",
    "\n",
    "outer_results_reg, outer_results_cls, feats_list, best_params_reg, best_params_cls, fold_scalers, fold_selectors, models_reg, models_cls = run_outer_cv_loop(\n",
    "    X, y_reg, y_cls, kf, X.columns.tolist(),\n",
    "    MODEL_REGRESSORS=MODEL_REGRESSORS,\n",
    "    MODEL_CLASSIFIERS=MODEL_CLASSIFIERS,\n",
    "    STACKING_META_REGRESSOR_CANDIDATES=META_REG_CANDS,\n",
    "    STACKING_META_CLASSIFIER_CANDIDATES=META_CLS_CANDS,\n",
    "    OPTIMIZATION_FUNCTIONS_REG=OPT_FUNCS_REG,\n",
    "    OPTIMIZATION_FUNCTIONS_CLS=OPT_FUNCS_CLS,\n",
    "    run_optuna_study=run_optuna_study,\n",
    "    select_best_stack=select_best_stack,\n",
    "    get_compute_device_params=lambda: {'xgb_tree_method': 'hist', 'lgbm_device': 'cpu'},\n",
    "    TUNE_ALL_BASE_MODELS=False\n",
    ")\n",
    "print('Outer CV completed')\n",
    "assert len(outer_results_reg['R2']) == config.N_SPLITS_OUTER_CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4332ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = aggregate_cv_results(outer_results_reg, outer_results_cls)\n",
    "(final_reg, final_cls, final_scaler, final_selectors, sel_feats_final, best_fold_reg, best_fold_cls) = select_final_model(\n",
    "    outer_results_reg,\n",
    "    outer_results_cls,\n",
    "    models_reg,\n",
    "    models_cls,\n",
    "    fold_scalers,\n",
    "    fold_selectors,\n",
    "    feats_list,\n",
    "    config.N_SPLITS_OUTER_CV\n",
    ")\n",
    "assert final_reg is not None and final_cls is not None\n",
    "print('Final models selected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd15a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_df, X_test_sel_reg_df, X_test_sel_cls_df, y_pred_reg_test, y_pred_cls_test = evaluate_on_test_set(\n",
    "    X.iloc[:40],\n",
    "    y_reg.iloc[:40],\n",
    "    y_cls.iloc[:40],\n",
    "    final_reg,\n",
    "    final_cls,\n",
    "    final_scaler,\n",
    "    final_selectors,\n",
    "    sel_feats_final,\n",
    "    X.columns.tolist()\n",
    ")\n",
    "assert y_pred_reg_test is not None and y_pred_cls_test is not None\n",
    "print('Evaluation step succeeded')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
